{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deluxe-needle",
   "metadata": {},
   "source": [
    "Don't edit. Should be copy of WSD_analysis_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "young-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "following-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dev_filename = 'data/BEM-WiC-preds/XLM-R_05_unbal_base_epochs/epoch_{0}/preds_dev.{1}-{1}.data'\n",
    "pred_test_filename = 'data/BEM-WiC-preds/XLM-R_05_unbal_base_epochs/epoch_{0}/preds_test.{1}-{1}.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "seventh-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_preds(pred_filename):\n",
    "    with open(pred_filename) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "written-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev_files = 'data/MCL-WiC/dev/multilingual/dev.{0}-{0}'\n",
    "data_test_files = 'data/MCL-WiC/test/multilingual/test.{0}-{0}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vulnerable-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_data_samples(data_files):\n",
    "    with open(data_files + '.data') as f_data, open(data_files + '.gold') as f_labels:\n",
    "        data_json = json.load(f_data)\n",
    "        labels_json = json.load(f_labels)\n",
    "    \n",
    "    labels_dict = {sample['id']: sample for sample in labels_json}\n",
    "    for sample in data_json:\n",
    "        sample['tag'] = labels_dict[sample['id']]['tag']\n",
    "\n",
    "    return data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "junior-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_test_data_samples(data_files):\n",
    "    with open(data_files + '.data') as f_data:\n",
    "        data_json = json.load(f_data)\n",
    "\n",
    "    return data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "choice-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_samples(data_files, pred_filename, with_labels=True):\n",
    "    preds = construct_preds(pred_filename)\n",
    "    if with_labels:\n",
    "        samples = construct_data_samples(data_files)\n",
    "    else:\n",
    "        samples = construct_test_data_samples(data_files)\n",
    "    \n",
    "    preds_dict = {pred['id']: pred for pred in preds}\n",
    "\n",
    "    for sample in samples:\n",
    "        pred = preds_dict[sample['id']]\n",
    "        for key, value in pred.items():\n",
    "            sample[key] = value\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "decent-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indoor-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsPredictor(ABC):\n",
    "    @abstractmethod\n",
    "    def predict(self, probs_1, probs_2):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict_proba(self, probs_1, probs_2):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "impaired-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivergencePredictor(AbsPredictor):\n",
    "    def __init__(self, threshold, normalize=True, divergence='Kullback–Leibler'):\n",
    "        assert divergence in ['Kullback–Leibler', 'Jensen–Shannon']\n",
    "        \n",
    "        self.threshold = threshold\n",
    "        self.normalize = normalize\n",
    "        self.divergence = divergence\n",
    "        \n",
    "    @staticmethod\n",
    "    def _kullback_leibler(probs_1, probs_2):\n",
    "        return sum(probs_1 * np.log(probs_1 / probs_2))\n",
    "        \n",
    "    def predict_proba(self, probs_1, probs_2):\n",
    "        if len(probs_1) < 2:\n",
    "            return True\n",
    "        \n",
    "        lst_probs_1, lst_probs_2 = [], []\n",
    "        for key in probs_1:\n",
    "            lst_probs_1.append(probs_1[key])\n",
    "            lst_probs_2.append(probs_2[key])\n",
    "            \n",
    "        lst_probs_1 = np.array(lst_probs_1, dtype=np.float128)\n",
    "        lst_probs_2 = np.array(lst_probs_2, dtype=np.float128)\n",
    "            \n",
    "        lst_probs_1 = np.exp(lst_probs_1) / sum(np.exp(lst_probs_1))\n",
    "        lst_probs_2 = np.exp(lst_probs_2) / sum(np.exp(lst_probs_2))\n",
    "        \n",
    "        if self.divergence == 'Kullback–Leibler':\n",
    "            diver = self._kullback_leibler(lst_probs_1, lst_probs_2)\n",
    "        elif self.divergence == 'Jensen–Shannon':\n",
    "            m = (lst_probs_1 + lst_probs_2) / 2\n",
    "            diver = (self._kullback_leibler(lst_probs_1, m)\n",
    "                   + self._kullback_leibler(lst_probs_2, m)) / 2\n",
    "        \n",
    "        if self.normalize:\n",
    "            diver /= len(probs_1)\n",
    "        \n",
    "        return diver\n",
    "    \n",
    "    def predict(self, probs_1, probs_2):\n",
    "        return self.predict_proba(probs_1, probs_2) < self.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "literary-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbsDotPredictor(AbsPredictor):\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def predict_proba(self, probs_1, probs_2):\n",
    "        lst_probs_1, lst_probs_2 = [], []\n",
    "        for key in probs_1:\n",
    "            lst_probs_1.append(probs_1[key])\n",
    "            lst_probs_2.append(probs_2[key])\n",
    "            \n",
    "        lst_probs_1 = np.array(lst_probs_1, dtype=np.float128)\n",
    "        lst_probs_2 = np.array(lst_probs_2, dtype=np.float128)\n",
    "            \n",
    "        lst_probs_1 = np.exp(lst_probs_1) / sum(np.exp(lst_probs_1))\n",
    "        lst_probs_2 = np.exp(lst_probs_2) / sum(np.exp(lst_probs_2))\n",
    "        \n",
    "        return sum(lst_probs_1 * lst_probs_2)\n",
    "    \n",
    "    def predict(self, probs_1, probs_2):\n",
    "        return self.predict_proba(probs_1, probs_2) > self.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cellular-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorsDotPredictor(AbsPredictor):\n",
    "    def __init__(self, threshold, normalize=True, norm_ord=2):\n",
    "        self.threshold = threshold\n",
    "        self.normalize = normalize\n",
    "        self.norm_ord = norm_ord\n",
    "    \n",
    "    def predict(self, out_vector_1, out_vector_2):\n",
    "        return self.predict_proba(out_vector_1, out_vector_2) > self.threshold\n",
    "    \n",
    "    def predict_proba(self, out_vector_1, out_vector_2):\n",
    "        out_vector_1 = np.array(out_vector_1)\n",
    "        out_vector_2 = np.array(out_vector_2)\n",
    "        \n",
    "        if self.normalize:\n",
    "            out_vector_1 /= np.linalg.norm(out_vector_1, ord=self.norm_ord)\n",
    "            out_vector_2 /= np.linalg.norm(out_vector_2, ord=self.norm_ord)\n",
    "            \n",
    "        return sum(out_vector_1 * out_vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "passive-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorsDistPredictor(AbsPredictor):\n",
    "    def __init__(self, threshold, normalize=True, norm_ord=2):\n",
    "        self.threshold = threshold\n",
    "        self.normalize = normalize\n",
    "        self.norm_ord = norm_ord\n",
    "    \n",
    "    def predict(self, out_vector_1, out_vector_2):\n",
    "        return self.predict_proba(out_vector_1, out_vector_2) < self.threshold\n",
    "    \n",
    "    def predict_proba(self, out_vector_1, out_vector_2):\n",
    "        out_vector_1 = np.array(out_vector_1)\n",
    "        out_vector_2 = np.array(out_vector_2)\n",
    "        \n",
    "        if self.normalize:\n",
    "            out_vector_1 /= np.linalg.norm(out_vector_1, ord=self.norm_ord)\n",
    "            out_vector_2 /= np.linalg.norm(out_vector_2, ord=self.norm_ord)\n",
    "        \n",
    "        return np.linalg.norm(out_vector_1 - out_vector_2, ord=self.norm_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "phantom-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs_predictions(predictor, samples):\n",
    "    return [predictor.predict(sample['probs1'], sample['probs2']) for sample in samples]\n",
    "\n",
    "def get_contexts_predictions(predictor, samples):\n",
    "    return [predictor.predict(sample['context_output1'], sample['context_output2']) for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bearing-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_threshold(predictor_class, get_predictions, samples, y_true, thresholds, **args):\n",
    "    scores = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = get_predictions(predictor_class(threshold=threshold, **args), samples)\n",
    "        scores.append(accuracy_score(y_true, y_pred))\n",
    "        \n",
    "    return max(scores), thresholds[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "august-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vectors_dot(dev_samples, y_dev_true, test_samples, y_test_true, filename):\n",
    "    _, dev_threshold = get_best_threshold(VectorsDotPredictor, get_contexts_predictions, dev_samples, y_dev_true, \n",
    "                                   np.linspace(0.6, 1, 100), normalize=True, norm_ord=2)\n",
    "\n",
    "    test_score = accuracy_score(y_test_true, get_contexts_predictions(\n",
    "        VectorsDotPredictor(threshold=dev_threshold, normalize=True, norm_ord=2),\n",
    "        test_samples))\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f'Dot Embs, p=2: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spectacular-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vectors_dist_2(dev_samples, y_dev_true, test_samples, y_test_true, filename):\n",
    "    _, dev_threshold = get_best_threshold(VectorsDistPredictor, get_contexts_predictions, dev_samples, y_dev_true, \n",
    "                np.linspace(0, 1, 100), normalize=True, norm_ord=2)\n",
    "\n",
    "    test_score = accuracy_score(y_test_true, get_contexts_predictions(\n",
    "            VectorsDistPredictor(threshold=dev_threshold, normalize=True, norm_ord=2),\n",
    "            test_samples))\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f'Dist Embs, p=2: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dental-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vectors_dist_1(dev_samples, y_dev_true, test_samples, y_test_true, filename):\n",
    "    _, dev_threshold = get_best_threshold(VectorsDistPredictor, get_contexts_predictions, dev_samples, y_dev_true, \n",
    "                np.linspace(0, 1, 100), normalize=True, norm_ord=1)\n",
    "\n",
    "    test_score = accuracy_score(y_test_true, get_contexts_predictions(\n",
    "            VectorsDistPredictor(threshold=dev_threshold, normalize=True, norm_ord=1),\n",
    "            test_samples))\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f'Dist Embs, p=1: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "together-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dot_probs(dev_samples, y_dev_true, test_samples, y_test_true, filename):\n",
    "    _, dev_threshold = get_best_threshold(ProbsDotPredictor, get_probs_predictions,\n",
    "                                          dev_samples, y_dev_true, np.linspace(0, 1, 100))\n",
    "\n",
    "    test_score = accuracy_score(y_test_true, get_probs_predictions(\n",
    "        ProbsDotPredictor(threshold=dev_threshold),\n",
    "        test_samples))\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f'Dot Probs: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "allied-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_probs_jen_shen(dev_samples, y_dev_true, test_samples, y_test_true, filename):\n",
    "    _, dev_threshold = get_best_threshold(DivergencePredictor, get_probs_predictions, dev_samples, y_dev_true, \n",
    "                np.linspace(0, 1, 300), divergence='Jensen–Shannon', normalize=False)\n",
    "\n",
    "    test_score = accuracy_score(y_test_true, get_probs_predictions(\n",
    "            DivergencePredictor(threshold=dev_threshold, divergence='Jensen–Shannon', normalize=False),\n",
    "            test_samples))\n",
    "\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f'Jen-Shen Probs: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "persistent-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['en', 'ru', 'fr', 'ar', 'zh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "based-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_num = 20\n",
    "base_dir = 'data/BEM-WiC-epoch-scores/XLMR_Base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "helpful-paragraph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f936cbfa1b994ed3837f438cb0727b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, 1 + epochs_num)):\n",
    "    for lang in langs:\n",
    "        dev_samples = construct_samples(data_dev_files.format(lang), pred_dev_filename.format(epoch, lang))\n",
    "        test_samples = construct_samples(data_test_files.format(lang), pred_test_filename.format(epoch, lang))\n",
    "\n",
    "        y_dev_true = [sample['tag'] == 'T' for sample in dev_samples]\n",
    "        y_test_true = [sample['tag'] == 'T' for sample in test_samples]\n",
    "        \n",
    "        epoch_dir = os.path.join(base_dir, f'epoch_{epoch}')\n",
    "        os.makedirs(epoch_dir, exist_ok=True)\n",
    "        out_filename = os.path.join(epoch_dir, f'{lang}.txt')\n",
    "        \n",
    "        if lang == 'en':\n",
    "            save_dot_probs(dev_samples, y_dev_true, test_samples, y_test_true, out_filename)\n",
    "            save_probs_jen_shen(dev_samples, y_dev_true, test_samples, y_test_true, out_filename)\n",
    "        \n",
    "        save_vectors_dot(dev_samples, y_dev_true, test_samples, y_test_true, out_filename)\n",
    "        save_vectors_dist_2(dev_samples, y_dev_true, test_samples, y_test_true, out_filename)\n",
    "        save_vectors_dist_1(dev_samples, y_dev_true, test_samples, y_test_true, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-person",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
